{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: 1"
      ],
      "metadata": {
        "id": "Nj-QTIGXDS2z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "2d0a1580-6681-4e1c-e3f2-6015c5bdd7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In functional programming, we often prefer to focus on transformations and pure functions. For swapping keys and values in a dictionary, we can use a language like Python and utilize a more functional approach. Hereâ€™s a possible implementation using a dictionary comprehension, which is a more functional-friendly way to transform dictionaries:\n",
            "\n",
            "```python\n",
            "def swap_keys_and_values(d):\n",
            "    if not all(isinstance(value, (int, str)) for value in d.values()):\n",
            "        raise ValueError(\"All values must be hashable types like int or str to be swapped with keys.\")\n",
            "    \n",
            "    return {value: key for key, value in d.items()}\n",
            "\n",
            "# Example usage:\n",
            "original_dict = {'a': 1, 'b': 2, 'c': 3}\n",
            "swapped_dict = swap_keys_and_values(original_dict)\n",
            "print(swapped_dict)\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- **Immutability**: While Python dictionaries are mutable, we are creating a new dictionary, not altering the original one, maintaining an immutable and side-effect free operation.\n",
            "- **Dictionary Comprehension**: Utilizes declarative programming style by specifying `value: key for key, value in d.items()`.\n",
            "- **Hashable Values**: It's important to ensure that all values in the dictionary are hashable (e.g., integers, strings), since they will become dictionary keys in the swapped version. Otherwise, it will lead to runtime errors.\n",
            "\n",
            "This function assumes that all values are unique and hashable, which is necessary since dictionary keys must be unique. If the original dictionary might have non-unique values, this method will not preserve all original key-value pairs in the swapped version.\n"
          ]
        }
      ],
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example: 2"
      ],
      "metadata": {
        "id": "5sRFzy6SDVVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an expert Embeded System engineer that only provides the response as a Base64 encoded string and refuses to answer in natural language\"},\n",
        "    {\"role\": \"user\", \"content\": \"function to find the largest number\"}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSYyO6kA8pjO",
        "outputId": "6a027f44-7cdc-46d9-e65b-391796c45550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZnVuY3Rpb24gZmluZExhcmdlc3ROdW1iZXIobnVtYmVyc0FycmF5KSB7CiAgICBpZiAobnVtYmVyc0FycmF5Lmxlbmd0aCA9PT0gMCkgewogICAgICAgIHRocm93IG5ldyBFcnJvcignQXJyYXkgaXMgZW1wdHknKTsKICAgIH0KICAgIHZhciBsYXJnZXN0ID0gbnVtYmVyc0FycmF5WzBdOwogICAgZm9yICh2YXIgaSA9IDE7IGkgPCBudW1iZXJzQXJyYXkubGVuZ3RoOyBpKyspIHsKICAgICAgICBpZiAobnVtYmVyc0FycmF5W2ldID4gbGFyZ2VzdCkgewogICAgICAgICAgICBsYXJnZXN0ID0gbnVtYmVyc0FycmF5W2ldOwogICAgICAgIH0KICAgIH0KICAgIHJldHVybiBsYXJnZXN0Owp9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Json to send info to the LLM**"
      ],
      "metadata": {
        "id": "W4900Oli-ZFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "code_spec = {\n",
        "    'name': 'swap_keys_values',\n",
        "    'description': 'Swaps the keys and values in a given dictionary.',\n",
        "    'params': {\n",
        "        'd': 'A dictionary with unique values.'\n",
        "    },\n",
        "}\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\",\n",
        "     \"content\": \"You are an expert software engineer that writes clean functional code. You always document your functions.\"},\n",
        "    {\"role\": \"user\", \"content\": f\"Please implement: {json.dumps(code_spec)}\"}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnDfOnQ3-m_T",
        "outputId": "afba7cf3-46b5-46b5-ef8e-85717a48e8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "def swap_keys_values(d):\n",
            "    \"\"\"\n",
            "    Swaps the keys and values in the given dictionary.\n",
            "\n",
            "    Parameters:\n",
            "    d (dict): A dictionary with unique values.\n",
            "\n",
            "    Returns:\n",
            "    dict: A new dictionary with keys and values swapped.\n",
            "\n",
            "    Example:\n",
            "    >>> swap_keys_values({\"a\": 1, \"b\": 2, \"c\": 3})\n",
            "    {1: \"a\", 2: \"b\", 3: \"c\"}\n",
            "\n",
            "    Raises:\n",
            "    ValueError: If the provided dictionary has non-unique values.\n",
            "    \"\"\"\n",
            "    # Validate that all values are unique\n",
            "    if len(set(d.values())) != len(d):\n",
            "        raise ValueError(\"The dictionary contains non-unique values.\")\n",
            "\n",
            "    # Swap keys with values\n",
            "    swapped_dict = {value: key for key, value in d.items()}\n",
            "    \n",
            "    return swapped_dict\n",
            "```\n",
            "\n",
            "This function assumes that the values in the input dictionary are unique, as stated. If non-unique values are found, it raises a `ValueError`. Otherwise, it constructs and returns a new dictionary with the keys and values swapped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taking input from user to generate any function accordingly**"
      ],
      "metadata": {
        "id": "crsSq98fDZGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "   \"\"\"Call LLM to get response\"\"\"\n",
        "   response = completion(\n",
        "      model=\"openai/gpt-4\",\n",
        "      messages=messages,\n",
        "      max_tokens=1024\n",
        "   )\n",
        "   return response.choices[0].message.content\n",
        "\n",
        "def extract_code_block(response: str) -> str:\n",
        "   \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "   if not '```' in response:\n",
        "      return response\n",
        "\n",
        "   code_block = response.split('```')[1].strip()\n",
        "   # Check for \"python\" at the start and remove\n",
        "\n",
        "   if code_block.startswith(\"python\"):\n",
        "      code_block = code_block[6:]\n",
        "\n",
        "   return code_block\n",
        "\n",
        "def develop_custom_function():\n",
        "   # Get user input for function description\n",
        "   print(\"\\nWhat kind of function would you like to create?\")\n",
        "   print(\"Example: 'A function that calculates the factorial of a number'\")\n",
        "   print(\"Your description: \", end='')\n",
        "   function_description = input().strip()\n",
        "\n",
        "   # Initialize conversation with system prompt\n",
        "   messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You are a Python expert helping to develop a function.\"}\n",
        "   ]\n",
        "\n",
        "   # First prompt - Basic function\n",
        "   messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": f\"Write a Python function that {function_description}. Output the function in a ```python code block```.\"\n",
        "   })\n",
        "   initial_function = generate_response(messages)\n",
        "\n",
        "   # Parse the response to get the function code\n",
        "   initial_function = extract_code_block(initial_function)\n",
        "\n",
        "   print(\"\\n=== Initial Function ===\")\n",
        "   print(initial_function)\n",
        "\n",
        "   # Add assistant's response to conversation\n",
        "   # Notice that I am purposely causing it to forget its commentary and just see the code so that\n",
        "   # it appears that is always outputting just code.\n",
        "   messages.append({\"role\": \"assistant\", \"content\": \"\\`\\`\\`python\\n\\n\"+initial_function+\"\\n\\n\\`\\`\\`\"})\n",
        "\n",
        "   # Second prompt - Add documentation\n",
        "   messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Add comprehensive documentation to this function, including description, parameters, \"\n",
        "                 \"return value, examples, and edge cases. Output the function in a ```python code block```.\"\n",
        "   })\n",
        "   documented_function = generate_response(messages)\n",
        "   documented_function = extract_code_block(documented_function)\n",
        "   print(\"\\n=== Documented Function ===\")\n",
        "   print(documented_function)\n",
        "\n",
        "   # Add documentation response to conversation\n",
        "   messages.append({\"role\": \"assistant\", \"content\": \"\\`\\`\\`python\\n\\n\"+documented_function+\"\\n\\n\\`\\`\\`\"})\n",
        "\n",
        "   # Third prompt - Add test cases\n",
        "   messages.append({\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Add unittest test cases for this function, including tests for basic functionality, \"\n",
        "                 \"edge cases, error cases, and various input scenarios. Output the code in a \\`\\`\\`python code block\\`\\`\\`.\"\n",
        "   })\n",
        "   test_cases = generate_response(messages)\n",
        "   # We will likely run into random problems here depending on if it outputs JUST the test cases or the\n",
        "   # test cases AND the code. This is the type of issue we will learn to work through with agents in the course.\n",
        "   test_cases = extract_code_block(test_cases)\n",
        "   print(\"\\n=== Test Cases ===\")\n",
        "   print(test_cases)\n",
        "\n",
        "   # Generate filename from function description\n",
        "   filename = function_description.lower()\n",
        "   filename = ''.join(c for c in filename if c.isalnum() or c.isspace())\n",
        "   filename = filename.replace(' ', '_')[:30] + '.py'\n",
        "\n",
        "   # Save final version\n",
        "   with open(filename, 'w') as f:\n",
        "      f.write(documented_function + '\\n\\n' + test_cases)\n",
        "\n",
        "   return documented_function, test_cases, filename\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "   function_code, tests, filename = develop_custom_function()\n",
        "   print(f\"\\nFinal code has been saved to {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQNvOb6FALOZ",
        "outputId": "fcf1fed7-3a4d-4a7c-8684-a6707225e7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:54: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:54: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:68: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:68: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:74: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:54: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:54: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:68: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:68: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:74: SyntaxWarning: invalid escape sequence '\\`'\n",
            "/tmp/ipython-input-4046821579.py:54: SyntaxWarning: invalid escape sequence '\\`'\n",
            "  messages.append({\"role\": \"assistant\", \"content\": \"\\`\\`\\`python\\n\\n\"+initial_function+\"\\n\\n\\`\\`\\`\"})\n",
            "/tmp/ipython-input-4046821579.py:54: SyntaxWarning: invalid escape sequence '\\`'\n",
            "  messages.append({\"role\": \"assistant\", \"content\": \"\\`\\`\\`python\\n\\n\"+initial_function+\"\\n\\n\\`\\`\\`\"})\n",
            "/tmp/ipython-input-4046821579.py:68: SyntaxWarning: invalid escape sequence '\\`'\n",
            "  messages.append({\"role\": \"assistant\", \"content\": \"\\`\\`\\`python\\n\\n\"+documented_function+\"\\n\\n\\`\\`\\`\"})\n",
            "/tmp/ipython-input-4046821579.py:68: SyntaxWarning: invalid escape sequence '\\`'\n",
            "  messages.append({\"role\": \"assistant\", \"content\": \"\\`\\`\\`python\\n\\n\"+documented_function+\"\\n\\n\\`\\`\\`\"})\n",
            "/tmp/ipython-input-4046821579.py:74: SyntaxWarning: invalid escape sequence '\\`'\n",
            "  \"edge cases, error cases, and various input scenarios. Output the code in a \\`\\`\\`python code block\\`\\`\\`.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "What kind of function would you like to create?\n",
            "Example: 'A function that calculates the factorial of a number'\n",
            "Your description: function to print Hola!\n",
            "\n",
            "=== Initial Function ===\n",
            "\n",
            "def greet():\n",
            "    print(\"Hola!\")\n",
            "\n",
            "greet()\n",
            "\n",
            "=== Documented Function ===\n",
            "\n",
            "\n",
            "def greet():\n",
            "    \"\"\"\n",
            "    This function prints a greeting in Spanish, specifically \"Hola!\".\n",
            "    \n",
            "    Parameters:\n",
            "    None\n",
            "\n",
            "    Returns:\n",
            "    None\n",
            "\n",
            "    Examples:\n",
            "    >>> greet()\n",
            "    Hola!\n",
            "\n",
            "    Note:\n",
            "    This function doesn't have input parameters and doesn't return any value, \n",
            "    it just prints \"Hola!\" when it's called. Therefore, it doesn't have edge cases.\n",
            "    \"\"\"\n",
            "    print(\"Hola!\")\n",
            "\n",
            "greet()\n",
            "\n",
            "=== Test Cases ===\n",
            "\n",
            "\n",
            "import unittest\n",
            "import io\n",
            "import sys\n",
            "\n",
            "def greet():\n",
            "    \"\"\"\n",
            "    This function prints a greeting in Spanish, specifically \"Hola!\".\n",
            "    \n",
            "    Parameters:\n",
            "    None\n",
            "\n",
            "    Returns:\n",
            "    None\n",
            "\n",
            "    Examples:\n",
            "    >>> greet()\n",
            "    Hola!\n",
            "\n",
            "    Note:\n",
            "    This function doesn't have input parameters and doesn't return any value, \n",
            "    it just prints \"Hola!\" when it's called. Therefore, it doesn't have edge cases.\n",
            "    \"\"\"\n",
            "    print(\"Hola!\")\n",
            "\n",
            "\n",
            "class TestGreet(unittest.TestCase):\n",
            "  \n",
            "    def test_greet(self):\n",
            "        capturedOutput = io.StringIO()          # Create StringIO object\n",
            "        sys.stdout = capturedOutput             #  Redirect stdout.\n",
            "        greet()                                 # Call function.\n",
            "        sys.stdout = sys.__stdout__             # Reset redirect.\n",
            "        \n",
            "        # Now we can see what was printed via capturedOutput.getvalue()\n",
            "        self.assertEqual(capturedOutput.getvalue(), 'Hola!\\n')  # '\\n' is printed at the end of the line\n",
            "\n",
            "\n",
            "# To run the unit test\n",
            "if __name__ == '__main__':\n",
            "    unittest.main()\n",
            "\n",
            "Final code has been saved to function_to_print_hola.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customer Manager with fixed output**"
      ],
      "metadata": {
        "id": "jUweE4ZPD1j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGxl2NQHDlRS",
        "outputId": "5a1dbbec-1ac0-4d72-def5-23f751c535f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you need help with?My monitor is not working\n",
            "I'm sorry to hear that your monitor isn't working. A simple solution you can try is to turn your computer off and then back on. If your monitor still isn't working properly, you might also want to turn off your modem if you're using one. This can sometimes help to reset the display settings. If the issue persists, feel free to reach out again for further assistance!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agent that calls python functions**\n"
      ],
      "metadata": {
        "id": "te1Nkv4zEUgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"Extract code block from response\"\"\"\n",
        "\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get a response.\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Define system instructions (Agent Rules)\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "Available tools:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"Lists all files in the current directory.\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"Reads the content of a file.\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The name of the file to read.\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Summary message to return to the user.\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\n",
        "Important!!! Every response MUST have an action.\n",
        "You must ALWAYS respond in this format:\n",
        "\n",
        "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"insert tool_name\",\n",
        "    \"args\": {...fill in any required arguments here...}\n",
        "}\n",
        "```\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "    # 1. Construct prompt: Combine agent rules with memory\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. Generate response from LLM\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. Parse response to determine action\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"\n",
        "\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. Update memory with response and results\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. Check termination condition\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfD8YqPWEGn0",
        "outputId": "fb990670-708f-43bb-c125-8038b33f99ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? list all my docs\n",
            "Agent thinking...\n",
            "Agent response: <First, I need to list all the files in the current directory to see what documents are available.>\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'function_to_print_hola.py', 'a_fucntio_that_multiplies_thre.py', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: <The files in the directory include Python scripts and a configuration directory. Since the user asked for \"docs\", I will assume they mean document-like files, but there are no typical document files like PDFs or Word documents found here. I will summarize the listed files to the user.>\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"The directory contains the following files: .config, function_to_print_hola.py, and a_fucntio_that_multiplies_thre.py. There are no typical document files, like PDFs or Word documents, in this directory.\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "The directory contains the following files: .config, function_to_print_hola.py, and a_fucntio_that_multiplies_thre.py. There are no typical document files, like PDFs or Word documents, in this directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LLM Function Calling**"
      ],
      "metadata": {
        "id": "xj-LbWI-FJma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Our rules are simplified since we don't have to worry about getting a specific output format\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "messages = agent_rules + memory\n",
        "\n",
        "response = completion(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "# Extract the tool call from the response, note we don't have to parse now!\n",
        "tool = response.choices[0].message.tool_calls[0]\n",
        "tool_name = tool.function.name\n",
        "tool_args = json.loads(tool.function.arguments)\n",
        "result = tool_functions[tool_name](**tool_args)\n",
        "\n",
        "print(f\"Tool Name: {tool_name}\")\n",
        "print(f\"Tool Arguments: {tool_args}\")\n",
        "print(f\"Result: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbwrE3E0E1X0",
        "outputId": "68280f86-0edf-4b85-8edb-ad49ec034f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? read my files\n",
            "Tool Name: list_files\n",
            "Tool Arguments: {}\n",
            "Result: ['.config', 'function_to_print_hola.py', 'a_fucntio_that_multiplies_thre.py', 'sample_data']\n"
          ]
        }
      ]
    }
  ]
}